{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import torch and device\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "if( torch.cuda.is_available()):\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "data_path= Path(\"../archive\")\n",
    "image_path = data_path / \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "path1=r\"C:\\Desktop files\\amaan files\\BMS stuff\\4th SEM\\python_programming\\python_project\\New Plant Diseases Dataset(Augmented)\"\n",
    "path2=\"../data/data/New Plant Diseases Dataset(Augmented)\"\n",
    "transforms = transforms.Compose([\n",
    "                                      transforms.CenterCrop(256),\n",
    "                                      transforms.ToTensor()])\n",
    "train_data=datasets.ImageFolder(path1+r'\\train',transform=transforms)\n",
    "test_data=datasets.ImageFolder(path1+r'\\valid',transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "train_dataloader=torch.utils.data.DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=4)\n",
    "test_dataloader=torch.utils.data.DataLoader(test_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "images,labels=next(iter(train_dataloader))\n",
    "\n",
    "#image=mpimg.imread(train_data[0][0])\n",
    "plt.imshow(torch.permute(train_data[10][0],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple___Apple_scab',\n",
       " 'Apple___Black_rot',\n",
       " 'Apple___Cedar_apple_rust',\n",
       " 'Apple___healthy',\n",
       " 'Blueberry___healthy',\n",
       " 'Cherry_(including_sour)___Powdery_mildew',\n",
       " 'Cherry_(including_sour)___healthy',\n",
       " 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
       " 'Corn_(maize)___Common_rust_',\n",
       " 'Corn_(maize)___Northern_Leaf_Blight',\n",
       " 'Corn_(maize)___healthy',\n",
       " 'Grape___Black_rot',\n",
       " 'Grape___Esca_(Black_Measles)',\n",
       " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
       " 'Grape___healthy',\n",
       " 'Orange___Haunglongbing_(Citrus_greening)',\n",
       " 'Peach___Bacterial_spot',\n",
       " 'Peach___healthy',\n",
       " 'Pepper,_bell___Bacterial_spot',\n",
       " 'Pepper,_bell___healthy',\n",
       " 'Potato___Early_blight',\n",
       " 'Potato___Late_blight',\n",
       " 'Potato___healthy',\n",
       " 'Raspberry___healthy',\n",
       " 'Soybean___healthy',\n",
       " 'Squash___Powdery_mildew',\n",
       " 'Strawberry___Leaf_scorch',\n",
       " 'Strawberry___healthy',\n",
       " 'Tomato___Bacterial_spot',\n",
       " 'Tomato___Early_blight',\n",
       " 'Tomato___Late_blight',\n",
       " 'Tomato___Leaf_Mold',\n",
       " 'Tomato___Septoria_leaf_spot',\n",
       " 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
       " 'Tomato___Target_Spot',\n",
       " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
       " 'Tomato___Tomato_mosaic_virus',\n",
       " 'Tomato___healthy']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names=train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,accuracy_fn):\n",
    "    loss,acc=0,0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,y in data_loader:\n",
    "            y_pred= model(X.to(device))\n",
    "\n",
    "            loss+= loss_fn(y_pred.to(device),y.to(device))\n",
    "            acc+= accuracy_fn(y_true=y.to(device),y_pred=y_pred.argmax(dim=1).to(device))\n",
    "        \n",
    "        # scale loss and acc to find average loss/acc per batch\n",
    "\n",
    "        loss/=len(data_loader)\n",
    "        acc/=len(data_loader)\n",
    "    return {\"model_name\":model.__class__.__name__,# only works when model was created with class},\n",
    "            \"model_loss\":loss.item(),\n",
    "            \"model_acc\":acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 256, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    #tiny VGG\n",
    "\n",
    "    def __init__(self, input_shape:int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,out_channels=hidden_units,\n",
    "                            kernel_size=3,stride=1,padding=1), \n",
    "                            nn.SiLU(),\n",
    "                            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,\n",
    "                            kernel_size=3,stride=1,padding=1),\n",
    "                            nn.SiLU(),\n",
    "                            nn.BatchNorm2d(40),\n",
    "                            nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "        \n",
    "        self.conv_block_2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,\n",
    "                            kernel_size=3,stride=1,padding=1), \n",
    "                            nn.SiLU(),\n",
    "                            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,\n",
    "                            kernel_size=3,stride=1,padding=1),\n",
    "                            nn.SiLU(),\n",
    "                            nn.BatchNorm2d(40),\n",
    "                            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            \n",
    "        )\n",
    "        self.conv_block_3=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,\n",
    "                            kernel_size=3,stride=1,padding=1), \n",
    "                            nn.SiLU(),\n",
    "                            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,\n",
    "                            kernel_size=3,stride=1,padding=1),\n",
    "                            nn.SiLU(),\n",
    "                            nn.BatchNorm2d(40),\n",
    "                            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            \n",
    "        )\n",
    "        self.conv_block_4=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,\n",
    "                            kernel_size=3,stride=1,padding=1), \n",
    "                            nn.SiLU(),\n",
    "                            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,\n",
    "                            kernel_size=3,stride=1,padding=1),\n",
    "                            nn.SiLU(),\n",
    "                            nn.BatchNorm2d(40),\n",
    "                            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            \n",
    "        )\n",
    "        self.conv_block_5=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,\n",
    "                            kernel_size=3,stride=1,padding=1), \n",
    "                            nn.SiLU(),\n",
    "                            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,\n",
    "                            kernel_size=3,stride=1,padding=1),\n",
    "                            nn.SiLU(),\n",
    "                            nn.BatchNorm2d(40),\n",
    "                            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*8*8,out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units,out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units,out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units,out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units,out_features=output_shape),\n",
    "            nn.Flatten(),        \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.conv_block_1(x)\n",
    "        #print(x.shape)\n",
    "        x=self.conv_block_2(x)\n",
    "        #print(x.shape)\n",
    "        x=self.conv_block_3(x)\n",
    "        x=self.conv_block_4(x)\n",
    "        x=self.conv_block_5(x)\n",
    "        x=self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\"\"\" model_2= CNN(input_shape=train_data[0][0].shape[0],hidden_units=40,output_shape=len(class_names)) \"\"\"\n",
    "model_2=torch.load(\"disease_model.pth\")\n",
    "model_2.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model_2.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "images = torch.randn(size=(BATCH_SIZE,3,256,256))\n",
    "test_image = images[0]\n",
    "print(f\"Image Batch Shape: {images.shape}\")\n",
    "print(f\"Single image shape: {test_image.shape}\")\n",
    "print(f\"Tests image: \\n {test_image}\")\n",
    "\"\"\" print(f\"data image: \\n {image}\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=nn.Sequential(nn.Conv2d(in_channels=3,out_channels=10,kernel_size=3,padding=1,stride=1),\n",
    "                 nn.ReLU(),\n",
    "nn.Conv2d(in_channels=10,out_channels=10,kernel_size=3,padding=1,stride=1),\n",
    "nn.ReLU())\n",
    "l2=nn.MaxPool2d(2,stride=2)\n",
    "x=l1(images)\n",
    "x=l2(x)\n",
    "#x=l1(x)\n",
    "#x=l2(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=nn.Sequential(nn.Conv2d(in_channels=10,out_channels=10,kernel_size=3,padding=1,stride=1)\n",
    ",nn.ReLU(),\n",
    "nn.Conv2d(in_channels=10,out_channels=10,kernel_size=3,padding=1,stride=1)\n",
    ",nn.ReLU())\n",
    "l2=nn.MaxPool2d(2)\n",
    "print(x.shape)\n",
    "x=l1(x)\n",
    "x=l2(x)\n",
    "print(x.shape)\n",
    "x=l1(x)\n",
    "x=l2(x)\n",
    "print(x.shape)\n",
    "l4=nn.Flatten()\n",
    "l4(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" for(X,y) in enumerate(train_dataloader):\n",
    "    print(X,y) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    gb=1024*4\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        \n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        acc=accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "        train_acc += acc\n",
    "        # 3. Optimizer zero grad\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(batch%100==0):\n",
    "            print(f\"Batch: {batch} \")\n",
    "            print(f\"Mem: {torch.cuda.memory_allocated()/gb}\")\n",
    "        print(f\"train_loss: {train_loss/(batch+1)} | train_acc: {train_acc/(batch+1)}\")\n",
    "        del loss,y_pred\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "@torch.inference_mode()\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "     \n",
    "    for X, y in data_loader:\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 1. Forward pass\n",
    "        test_pred = model(X)\n",
    "        \n",
    "        # 2. Calculate loss and accuracy\n",
    "        test_loss += loss_fn(test_pred, y)\n",
    "        test_acc += accuracy_fn(y_true=y,\n",
    "            y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "        )\n",
    "        \n",
    "    # Adjust metrics and print out\n",
    "    test_loss /= len(data_loader)\n",
    "    test_acc /= len(data_loader)\n",
    "    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true,y_pred):\n",
    "    correct=torch.eq(y_true,y_pred).sum().item()\n",
    "    acc= (correct/len(y_pred))*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_2.parameters(),lr=0.00001)\n",
    "#scheduler=torch.optim.lr_scheduler.StepLR(optimizer=optimizer,step_size=1,gamma=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "from timeit import default_timer as Timer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#train and test model\n",
    "\n",
    "epochs=1\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch : {epoch}\\n-------\")\n",
    "\n",
    "    train_step(\n",
    "        model=model_2,\n",
    "        data_loader=train_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_2_results = eval_model(\n",
    "    model=model_2,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_2.state_dict(),\"disease_model_state.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_2,\"disease_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
